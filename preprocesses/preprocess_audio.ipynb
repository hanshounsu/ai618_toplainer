{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.path.abspath('.')))\n",
    "import librosa\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from utils.util import *\n",
    "from functools import partial\n",
    "from multiprocessing import Pool\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import soundfile as sf\n",
    "\n",
    "PATH_MIX = './mdx/B/mdx-net-submission/data/test_mackenzie/'\n",
    "PATH = './mdx/B/mdx-net-submission/data/results_mackenzie/baseline/'\n",
    "mackenzie_list = list(Path(PATH_MIX).glob('*/mixture.wav'))\n",
    "mackenzie_vocal_list = list(Path(PATH).glob('*/vocals.wav'))\n",
    "mackenzie_bass_list = list(Path(PATH).glob('*/bass.wav'))\n",
    "mackenzie_drums_list = list(Path(PATH).glob('*/drums.wav'))\n",
    "mackenzie_others_list = list(Path(PATH).glob('*/other.wav'))\n",
    "SAMPLE_RATE = 16000\n",
    "print(len(mackenzie_list), len(mackenzie_vocal_list)) # Mackenzie의 Mixture(원본) 음성은 145개, Vocal 추출 음성은 131개임을 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Write guitar wav\n",
    "# num_write = 0\n",
    "# for mackenzie_v, mackenzie_b, mackenzie_d, mackenzie_o in zip(tqdm(mackenzie_vocal_list), mackenzie_bass_list, mackenzie_drums_list, mackenzie_others_list):\n",
    "#     assert str(mackenzie_v).split('/')[-2] == str(mackenzie_b).split('/')[-2] == str(mackenzie_d).split('/')[-2] == str(mackenzie_o).split('/')[-2]\n",
    "#     # title = str(mackenzie_m).split('/')[-2]\n",
    "#     # audio_m, sr = librosa.load(str(mackenzie_m), sr=SAMPLE_RATE, mono=True)\n",
    "#     # audio_v, sr = librosa.load(str(mackenzie_v), sr=SAMPLE_RATE, mono=True)\n",
    "#     audio_b, sr = librosa.load(str(mackenzie_b), sr=SAMPLE_RATE, mono=True)\n",
    "#     audio_d, sr = librosa.load(str(mackenzie_d), sr=SAMPLE_RATE, mono=True)\n",
    "#     audio_o, sr = librosa.load(str(mackenzie_o), sr=SAMPLE_RATE, mono=True)\n",
    "#     # audio_g_m = audio_m - audio_v\n",
    "#     audio_g_p = audio_b + audio_d + audio_o\n",
    "#     save_guitar_path = str(mackenzie_v).replace('vocals.wav','guitar.wav')\n",
    "#     sf.write(save_guitar_path, audio_g_p, samplerate=SAMPLE_RATE)\n",
    "#     # sf.write(f'../save/{title}_mixture_minus_guitar.wav', audio_g_m, samplerate=16000)\n",
    "#     # sf.write(f'../save/{title}_guitar_plus_others_plus_bass.wav', audio_g_p, samplerate=16000)\n",
    "\n",
    "mackenzie_guitar_list = list(Path(PATH).glob('*/guitar.wav'))\n",
    "print(len(mackenzie_guitar_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REF = 0.1\n",
    "threshold = 32000 # 2 sec\n",
    "# with Pool(6) as p:\n",
    "#     a = list(tqdm(p.imap(partial(obtain_start_end_of_mute, REF=REF, threshold=threshold), mackenzie_vocal_list),total=len(mackenzie_vocal_list)))\n",
    "# with open(f'/save/mackenzie_vocal_start_end_of_mute_{REF}_{threshold}.txt', 'wb') as f:\n",
    "#     pickle.dump(a, f)\n",
    "# del a\n",
    "with open(f'./save/mackenzie_vocal_start_end_of_mute_{REF}_{threshold}.txt', 'rb') as f:\n",
    "    mackenzie_vocal_start_end_of_mute = pickle.load(f)\n",
    "# with Pool(6) as p:\n",
    "#     b = list(tqdm(p.imap(partial(obtain_start_end_of_mute, REF=REF, threshold=threshold), mackenzie_guitar_list),total=len(mackenzie_guitar_list)))\n",
    "# with open(f'./save/mackenzie_guitar_start_end_of_mute_{REF}_{threshold}.txt', 'wb') as f:\n",
    "#     pickle.dump(b, f)\n",
    "# del b\n",
    "with open(f'./save/mackenzie_guitar_start_end_of_mute_{REF}_{threshold}.txt', 'rb') as f:\n",
    "    mackenzie_guitar_start_end_of_mute = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_mute_section = 0\n",
    "total_available_section = 0 # section larger than 5s\n",
    "total_available_length = 0 # section larger than 5s\n",
    "for filepath, audio, aligned_retain, mute_start_end in mackenzie_vocal_start_end_of_mute:\n",
    "    total_mute_section += len(mute_start_end)\n",
    "    prev_mute_end = 0\n",
    "    for mute_start, mute_end in mute_start_end:\n",
    "        # print(mute_start//SAMPLE_RATE, mute_end//SAMPLE_RATE)\n",
    "        if mute_start - prev_mute_end > 5.12*SAMPLE_RATE: # Mute가 아닌 기간이 5초가 넘는 경우?\n",
    "            total_available_section+=1\n",
    "            total_available_length+=mute_start-prev_mute_end\n",
    "        prev_mute_end = mute_end\n",
    "print(total_mute_section, total_available_section, total_available_length//SAMPLE_RATE/60/60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "현수님이 제일 좋아요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transpose(a,b):\n",
    "    '''\n",
    "    [[note1, note2, ...], [spec1, spec2, ...]] 꼴을\n",
    "    [(note1, spec1), (note2, spec2), ...] 꼴로 변환해줌\n",
    "    '''\n",
    "    return list(map(tuple, zip(a,b)))\n",
    "mackenzie_vocal_guitar = transpose(mackenzie_vocal_start_end_of_mute, mackenzie_guitar_start_end_of_mute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_mackenzie(tuples):\n",
    "    mackenzie_vocal_tuple, mackenzie_guitar_tuple = tuples\n",
    "    filepath, audio, aligned_retain, mute_start_end = mackenzie_vocal_tuple \n",
    "    filepath_, audio_, aligned_retain_, mute_start_end_ = mackenzie_guitar_tuple \n",
    "    assert str(filepath).split('/')[-2] == str(filepath_).split('/')[-2]\n",
    "    assert len(audio) == len(aligned_retain) == len(audio_) == len(aligned_retain_)\n",
    "    filename = str(filepath).split('/')[-2]\n",
    "\n",
    "    sum_retain = aligned_retain_ + aligned_retain\n",
    "    state = 0 # 1 means sound present, 0 means silent\n",
    "    start = 0\n",
    "    end = 0\n",
    "    available_segment_vocal = []\n",
    "    available_segment_guitar = []\n",
    "    for idx in range(len(audio)):\n",
    "        if idx == len(audio)-1:\n",
    "            if state == 1:\n",
    "                end = idx\n",
    "                if end - start >= 5.12*SAMPLE_RATE: # 5.12초로 변경?\n",
    "                    available_segment_vocal.append(audio[start: end])\n",
    "                    available_segment_guitar.append(audio_[start: end])\n",
    "        if state == 0 and sum_retain[idx] == 0:\n",
    "            state = 1\n",
    "            start = idx\n",
    "        elif state == 1 and sum_retain[idx] < 0:\n",
    "            state = 0\n",
    "            end = idx-1\n",
    "            if end - start >= 5.12*SAMPLE_RATE: # 5.12초로 변경?\n",
    "                available_segment_vocal.append(audio[start: end])\n",
    "                available_segment_guitar.append(audio_[start: end])\n",
    "    segment_num = 0\n",
    "    vocal_segments = []\n",
    "    guitar_segments = []\n",
    "    for segment_vocal, segment_guitar in zip(available_segment_vocal, available_segment_guitar):\n",
    "        assert segment_vocal.shape == segment_guitar.shape # 보컬과 기타의 shape이 같아야 하는 가정 설정문(assert)\n",
    "        sf.write(f'./segments/mackenzie/vocal/{filename}_{segment_num}.wav', segment_vocal, samplerate=SAMPLE_RATE)\n",
    "        sf.write(f'./segments/mackenzie/guitar/{filename}_{segment_num}.wav', segment_guitar, samplerate=SAMPLE_RATE)\n",
    "        segment_num += 1\n",
    "        vocal_segments.append(segment_vocal)\n",
    "        guitar_segments.append(segment_guitar)\n",
    "    return (vocal_segments, guitar_segments)\n",
    "    \n",
    "with Pool(6) as p:\n",
    "    vocal_guitar = list(tqdm(p.imap(segment_mackenzie, mackenzie_vocal_guitar),total=len(mackenzie_vocal_guitar)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocal_total = []\n",
    "guitar_total = []\n",
    "# vocal_wav = list(Path('./segments/mackenzie_norm/vocal').glob('*.wav'))\n",
    "# guitar_wav = list(Path('./segments/mackenzie_norm/guitar').glob('*.wav'))\n",
    "vocal_wav = list(Path('./segments/mackenzie/vocal').glob('*.wav'))\n",
    "guitar_wav = list(Path('./segments/mackenzie/guitar').glob('*.wav'))\n",
    "vocal_wav = sorted(vocal_wav)\n",
    "guitar_wav = sorted(guitar_wav)\n",
    "\n",
    "filename_list = []\n",
    "for filename in vocal_wav:\n",
    "    filename_ = '_'.join(str(filename).split('_')[:-1])\n",
    "    filename_list.append(filename_)\n",
    "filename_list = [*set(filename_list)]\n",
    "filename_list= sorted(filename_list)\n",
    "for i in filename_list:\n",
    "    print(i)\n",
    "filename_list_train = filename_list[:int(0.8*len(filename_list))+4]\n",
    "filename_list_test = filename_list[int(0.8*len(filename_list))+4:]\n",
    "segment_name_train = []\n",
    "segment_name_test = []\n",
    "for filename in vocal_wav:\n",
    "    if '_'.join(str(filename).split('_')[:-1]) in filename_list_train:\n",
    "        segment_name_train.append(filename)\n",
    "    elif '_'.join(str(filename).split('_')[:-1]) in filename_list_test:\n",
    "        segment_name_test.append(filename)\n",
    "    else:\n",
    "        raise ValueError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./feature/mackenzie_train_list_vocal.txt', 'w') as f:\n",
    "    for vocal in tqdm(segment_name_train):\n",
    "        f.write(str(vocal))\n",
    "        f.write('\\n')\n",
    "with open('./feature/mackenzie_test_list_vocal.txt', 'w') as f:\n",
    "    for vocal in tqdm(segment_name_test):\n",
    "        f.write(str(vocal))\n",
    "        f.write('\\n')\n",
    "# vocal : 716, test 179"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(segment_name_train), len(segment_name_test), segment_name_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./feature/mackenzie_train_list_vocal_norm.txt', 'r') as f:\n",
    "    mackenzie_train_list_vocal = f.read().splitlines()\n",
    "with open('./feature/mackenzie_test_list_vocal_norm.txt', 'r') as f:\n",
    "    mackenzie_test_list_vocal = f.read().splitlines()\n",
    "vocal_train = []\n",
    "guitar_train = []\n",
    "vocal_test = []\n",
    "guitar_test = []\n",
    "for train_vocal in tqdm(mackenzie_train_list_vocal):\n",
    "    train_guitar = train_vocal.replace('/vocal/','/guitar/')\n",
    "    wav_vocal, sr = sf.read(train_vocal)\n",
    "    wav_guitar, sr = sf.read(train_guitar)\n",
    "    wav_vocal = torch.tensor(wav_vocal, dtype=torch.float32)\n",
    "    wav_guitar = torch.tensor(wav_guitar, dtype=torch.float32)\n",
    "    vocal_train.append(wav_vocal)\n",
    "    guitar_train.append(wav_guitar)\n",
    "for test_vocal in tqdm(mackenzie_test_list_vocal):\n",
    "    test_guitar = test_vocal.replace('/vocal/','/guitar/')\n",
    "    wav_vocal, sr = sf.read(test_vocal)\n",
    "    wav_guitar, sr = sf.read(test_guitar)\n",
    "    wav_vocal = torch.tensor(wav_vocal, dtype=torch.float32)\n",
    "    wav_guitar = torch.tensor(wav_guitar, dtype=torch.float32)\n",
    "    vocal_test.append(wav_vocal)\n",
    "    guitar_test.append(wav_guitar)\n",
    "\n",
    "train_save_path = './feature/inpainting/mackenzie_unet_diffusion_inpainter_audio/train_norm.pt'\n",
    "test_save_path = './feature/inpainting/mackenzie_unet_diffusion_inpainter_audio/test_norm.pt'\n",
    "torch.save([vocal_train, guitar_train], train_save_path)\n",
    "torch.save([vocal_test, guitar_test], test_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make train test splits in wav in groundtruth\n",
    "import shutil\n",
    "with open('./feature/mackenzie_train_list_vocal_norm.txt', 'r') as f:\n",
    "    mackenzie_train_list_vocal = f.read().splitlines()\n",
    "with open('./feature/mackenzie_test_list_vocal_norm.txt', 'r') as f:\n",
    "    mackenzie_test_list_vocal = f.read().splitlines()\n",
    "for train_vocal in tqdm(mackenzie_train_list_vocal):\n",
    "    target_path = train_vocal.replace('segments/mackenzie_norm/vocal', 'save/groundtruth/mackenzie_norm/vocal/train')\n",
    "    shutil.copy(train_vocal, target_path)\n",
    "for test_vocal in tqdm(mackenzie_test_list_vocal):\n",
    "    target_path = test_vocal.replace('segments/mackenzie_norm/vocal', 'save/groundtruth/mackenzie_norm/vocal/test')\n",
    "    shutil.copy(test_vocal, target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdx-submit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "0d0f7d8b92394e68a45c255b67e157d22e0177512c8c4388f57e8ac0390f1c85"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
